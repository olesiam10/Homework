{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a neural network? What are the general steps required to build a neural network? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network is a series of algorithms that can effectively recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. Neural network is a powerful modeling approach that accounts for interactions between data really well.\n",
    "\n",
    "<b>The general steps required to build a neural network are:</b>\n",
    "\n",
    "* put together an input layer and define number of input nodes\n",
    "* a hidden layer or layers and define the number of nodes in these hidden layers\n",
    "* define the number of ourput nodes; number of output classes you want the neural network to process\n",
    "* define an activation function for each layer, for example, relu or linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generally, how do you check the performance of a neural network? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test model's performance, we use the validation data. Because the he model's performance on the training data is not a good indication of how it'd perform on new data. Validation data is the data that's only used to test model performance and nothing else. \n",
    "\n",
    "For the validation in deep learning, we use validation split rather than cross-validation, since deep learning is mostly used for larger datasets and cross validations take a lot of computational power. So we can specify the validation split when fitting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a neural network using keras to predict the outcome of either of these datasets: \n",
    "Cardiac Arrhythmia: https://archive.ics.uci.edu/ml/datasets/Arrhythmia \n",
    "Abalone age: https://archive.ics.uci.edu/ml/datasets/Abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#red the dataset file\n",
    "abalone_df = pd.read_csv(\"abalone_edited.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>lengths</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  lengths  Diameter  height  Whole weight  Shucked weight  \\\n",
       "0   M    0.455     0.365   0.095        0.5140          0.2245   \n",
       "1   M    0.350     0.265   0.090        0.2255          0.0995   \n",
       "2   F    0.530     0.420   0.135        0.6770          0.2565   \n",
       "3   M    0.440     0.365   0.125        0.5160          0.2155   \n",
       "4   I    0.330     0.255   0.080        0.2050          0.0895   \n",
       "\n",
       "   Viscera weight  Shell weight  Rings  \n",
       "0          0.1010         0.150     15  \n",
       "1          0.0485         0.070      7  \n",
       "2          0.1415         0.210      9  \n",
       "3          0.1140         0.155     10  \n",
       "4          0.0395         0.055      7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex                object\n",
       "lengths           float64\n",
       "Diameter          float64\n",
       "height            float64\n",
       "Whole weight      float64\n",
       "Shucked weight    float64\n",
       "Viscera weight    float64\n",
       "Shell weight      float64\n",
       "Rings               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking data types\n",
    "abalone_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping \"sex\" cilumn\n",
    "new = abalone_df.drop(\"Sex\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(new), columns = new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lengths</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.574558</td>\n",
       "      <td>-0.432149</td>\n",
       "      <td>-1.064424</td>\n",
       "      <td>-0.641898</td>\n",
       "      <td>-0.607685</td>\n",
       "      <td>-0.726212</td>\n",
       "      <td>-0.638217</td>\n",
       "      <td>1.571544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.448986</td>\n",
       "      <td>-1.439929</td>\n",
       "      <td>-1.183978</td>\n",
       "      <td>-1.230277</td>\n",
       "      <td>-1.170910</td>\n",
       "      <td>-1.205221</td>\n",
       "      <td>-1.212987</td>\n",
       "      <td>-0.910013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.122130</td>\n",
       "      <td>-0.107991</td>\n",
       "      <td>-0.309469</td>\n",
       "      <td>-0.463500</td>\n",
       "      <td>-0.356690</td>\n",
       "      <td>-0.207139</td>\n",
       "      <td>-0.289624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.699476</td>\n",
       "      <td>-0.432149</td>\n",
       "      <td>-0.347099</td>\n",
       "      <td>-0.637819</td>\n",
       "      <td>-0.648238</td>\n",
       "      <td>-0.607600</td>\n",
       "      <td>-0.602294</td>\n",
       "      <td>0.020571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.615544</td>\n",
       "      <td>-1.540707</td>\n",
       "      <td>-1.423087</td>\n",
       "      <td>-1.272086</td>\n",
       "      <td>-1.215968</td>\n",
       "      <td>-1.287337</td>\n",
       "      <td>-1.320757</td>\n",
       "      <td>-0.910013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lengths  Diameter    height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0 -0.574558 -0.432149 -1.064424     -0.641898       -0.607685       -0.726212   \n",
       "1 -1.448986 -1.439929 -1.183978     -1.230277       -1.170910       -1.205221   \n",
       "2  0.050033  0.122130 -0.107991     -0.309469       -0.463500       -0.356690   \n",
       "3 -0.699476 -0.432149 -0.347099     -0.637819       -0.648238       -0.607600   \n",
       "4 -1.615544 -1.540707 -1.423087     -1.272086       -1.215968       -1.287337   \n",
       "\n",
       "   Shell weight     Rings  \n",
       "0     -0.638217  1.571544  \n",
       "1     -1.212987 -0.910013  \n",
       "2     -0.207139 -0.289624  \n",
       "3     -0.602294  0.020571  \n",
       "4     -1.320757 -0.910013  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled.drop('Rings', axis=1)\n",
    "y = df_scaled['Rings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'RootMeanSquaredError'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 1s 3ms/step - loss: 0.7052 - mae: 0.5982 - root_mean_squared_error: 0.8376 - val_loss: 0.5106 - val_mae: 0.5271 - val_root_mean_squared_error: 0.7146\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.5410 - mae: 0.5302 - root_mean_squared_error: 0.7348 - val_loss: 0.4876 - val_mae: 0.5173 - val_root_mean_squared_error: 0.6983\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.5413 - mae: 0.5338 - root_mean_squared_error: 0.7347 - val_loss: 0.4725 - val_mae: 0.4964 - val_root_mean_squared_error: 0.6874\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.5055 - mae: 0.5048 - root_mean_squared_error: 0.7102 - val_loss: 0.4505 - val_mae: 0.4882 - val_root_mean_squared_error: 0.6712\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4832 - mae: 0.5008 - root_mean_squared_error: 0.6947 - val_loss: 0.4383 - val_mae: 0.4810 - val_root_mean_squared_error: 0.6620\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.5033 - mae: 0.5058 - root_mean_squared_error: 0.7086 - val_loss: 0.4283 - val_mae: 0.4746 - val_root_mean_squared_error: 0.6544\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4684 - mae: 0.4993 - root_mean_squared_error: 0.6839 - val_loss: 0.4179 - val_mae: 0.4655 - val_root_mean_squared_error: 0.6465\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4941 - mae: 0.4955 - root_mean_squared_error: 0.7027 - val_loss: 0.4117 - val_mae: 0.4625 - val_root_mean_squared_error: 0.6417\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.5025 - mae: 0.5073 - root_mean_squared_error: 0.7086 - val_loss: 0.4093 - val_mae: 0.4562 - val_root_mean_squared_error: 0.6398\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4749 - mae: 0.4894 - root_mean_squared_error: 0.6883 - val_loss: 0.4037 - val_mae: 0.4566 - val_root_mean_squared_error: 0.6353\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4470 - mae: 0.4833 - root_mean_squared_error: 0.6676 - val_loss: 0.4012 - val_mae: 0.4558 - val_root_mean_squared_error: 0.6334\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4452 - mae: 0.4789 - root_mean_squared_error: 0.6665 - val_loss: 0.4009 - val_mae: 0.4545 - val_root_mean_squared_error: 0.6332\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4765 - mae: 0.4915 - root_mean_squared_error: 0.6895 - val_loss: 0.3968 - val_mae: 0.4484 - val_root_mean_squared_error: 0.6299\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.5295 - mae: 0.5184 - root_mean_squared_error: 0.7270 - val_loss: 0.3955 - val_mae: 0.4476 - val_root_mean_squared_error: 0.6289\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4723 - mae: 0.4775 - root_mean_squared_error: 0.6868 - val_loss: 0.3950 - val_mae: 0.4503 - val_root_mean_squared_error: 0.6285\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4712 - mae: 0.4886 - root_mean_squared_error: 0.6849 - val_loss: 0.3968 - val_mae: 0.4469 - val_root_mean_squared_error: 0.6300\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4661 - mae: 0.4927 - root_mean_squared_error: 0.6825 - val_loss: 0.3971 - val_mae: 0.4528 - val_root_mean_squared_error: 0.6301\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4720 - mae: 0.4879 - root_mean_squared_error: 0.6863 - val_loss: 0.3973 - val_mae: 0.4445 - val_root_mean_squared_error: 0.6304\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4687 - mae: 0.4872 - root_mean_squared_error: 0.6839 - val_loss: 0.3920 - val_mae: 0.4470 - val_root_mean_squared_error: 0.6261\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4667 - mae: 0.4933 - root_mean_squared_error: 0.6826 - val_loss: 0.3897 - val_mae: 0.4525 - val_root_mean_squared_error: 0.6242\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4345 - mae: 0.4768 - root_mean_squared_error: 0.6586 - val_loss: 0.3921 - val_mae: 0.4486 - val_root_mean_squared_error: 0.6262\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4360 - mae: 0.4785 - root_mean_squared_error: 0.6599 - val_loss: 0.3911 - val_mae: 0.4493 - val_root_mean_squared_error: 0.6254\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4140 - mae: 0.4655 - root_mean_squared_error: 0.6428 - val_loss: 0.3882 - val_mae: 0.4449 - val_root_mean_squared_error: 0.6231\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4472 - mae: 0.4836 - root_mean_squared_error: 0.6685 - val_loss: 0.3897 - val_mae: 0.4450 - val_root_mean_squared_error: 0.6242\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4586 - mae: 0.4795 - root_mean_squared_error: 0.6767 - val_loss: 0.3874 - val_mae: 0.4472 - val_root_mean_squared_error: 0.6224\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4290 - mae: 0.4810 - root_mean_squared_error: 0.6547 - val_loss: 0.4028 - val_mae: 0.4679 - val_root_mean_squared_error: 0.6346\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4511 - mae: 0.4909 - root_mean_squared_error: 0.6714 - val_loss: 0.3868 - val_mae: 0.4444 - val_root_mean_squared_error: 0.6219\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4933 - mae: 0.4937 - root_mean_squared_error: 0.7011 - val_loss: 0.3888 - val_mae: 0.4431 - val_root_mean_squared_error: 0.6236\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4624 - mae: 0.4892 - root_mean_squared_error: 0.6795 - val_loss: 0.3855 - val_mae: 0.4503 - val_root_mean_squared_error: 0.6209\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4318 - mae: 0.4802 - root_mean_squared_error: 0.6560 - val_loss: 0.3848 - val_mae: 0.4434 - val_root_mean_squared_error: 0.6204\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4733 - mae: 0.4917 - root_mean_squared_error: 0.6869 - val_loss: 0.3843 - val_mae: 0.4468 - val_root_mean_squared_error: 0.6199\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4255 - mae: 0.4729 - root_mean_squared_error: 0.6518 - val_loss: 0.3840 - val_mae: 0.4431 - val_root_mean_squared_error: 0.6197\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4447 - mae: 0.4769 - root_mean_squared_error: 0.6662 - val_loss: 0.3826 - val_mae: 0.4444 - val_root_mean_squared_error: 0.6185\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4393 - mae: 0.4774 - root_mean_squared_error: 0.6624 - val_loss: 0.3862 - val_mae: 0.4501 - val_root_mean_squared_error: 0.6214\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4559 - mae: 0.4816 - root_mean_squared_error: 0.6744 - val_loss: 0.3842 - val_mae: 0.4391 - val_root_mean_squared_error: 0.6198\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4676 - mae: 0.4792 - root_mean_squared_error: 0.6833 - val_loss: 0.3836 - val_mae: 0.4433 - val_root_mean_squared_error: 0.6194\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4070 - mae: 0.4639 - root_mean_squared_error: 0.6377 - val_loss: 0.3818 - val_mae: 0.4467 - val_root_mean_squared_error: 0.6179\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4604 - mae: 0.4930 - root_mean_squared_error: 0.6782 - val_loss: 0.3830 - val_mae: 0.4480 - val_root_mean_squared_error: 0.6189\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4334 - mae: 0.4719 - root_mean_squared_error: 0.6576 - val_loss: 0.3834 - val_mae: 0.4433 - val_root_mean_squared_error: 0.6192\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4559 - mae: 0.4850 - root_mean_squared_error: 0.6749 - val_loss: 0.3819 - val_mae: 0.4418 - val_root_mean_squared_error: 0.6180\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4054 - mae: 0.4590 - root_mean_squared_error: 0.6362 - val_loss: 0.3874 - val_mae: 0.4533 - val_root_mean_squared_error: 0.6224\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.4022 - mae: 0.4593 - root_mean_squared_error: 0.6333 - val_loss: 0.3824 - val_mae: 0.4488 - val_root_mean_squared_error: 0.6184\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4534 - mae: 0.4842 - root_mean_squared_error: 0.6730 - val_loss: 0.3801 - val_mae: 0.4422 - val_root_mean_squared_error: 0.6165\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4297 - mae: 0.4688 - root_mean_squared_error: 0.6544 - val_loss: 0.3810 - val_mae: 0.4398 - val_root_mean_squared_error: 0.6172\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4705 - mae: 0.4888 - root_mean_squared_error: 0.6853 - val_loss: 0.3819 - val_mae: 0.4377 - val_root_mean_squared_error: 0.6180\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4228 - mae: 0.4653 - root_mean_squared_error: 0.6491 - val_loss: 0.3791 - val_mae: 0.4418 - val_root_mean_squared_error: 0.6157\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4302 - mae: 0.4742 - root_mean_squared_error: 0.6553 - val_loss: 0.3834 - val_mae: 0.4399 - val_root_mean_squared_error: 0.6192\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4442 - mae: 0.4744 - root_mean_squared_error: 0.6654 - val_loss: 0.3812 - val_mae: 0.4396 - val_root_mean_squared_error: 0.6174\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4653 - mae: 0.4840 - root_mean_squared_error: 0.6818 - val_loss: 0.3796 - val_mae: 0.4438 - val_root_mean_squared_error: 0.6161\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 0.4722 - mae: 0.4855 - root_mean_squared_error: 0.6867 - val_loss: 0.3788 - val_mae: 0.4387 - val_root_mean_squared_error: 0.6155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbee140f040>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=20, epochs = 50, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write another algorithm to predict the same result as the previous question using either KNN or logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logostic regression\n",
    "X = df_scaled.drop('Rings', axis=1) #scaling X\n",
    "y = new['Rings']\n",
    "\n",
    "#split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=50)\n",
    "\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a neural network using pytorch to predict the same result as question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5497,  0.5252,  0.1311,  ...,  0.2687, -0.0191,  0.1521],\n",
      "        [-0.3664, -0.3818, -0.2275,  ..., -0.5041, -0.2746, -0.5700],\n",
      "        [ 0.0500,  0.0717,  0.0116,  ..., -0.2202, -0.1195, -0.2431],\n",
      "        ...,\n",
      "        [-1.6572, -1.4903, -1.1840,  ..., -1.2362, -1.3193, -1.2705],\n",
      "        [-0.4496, -0.3314, -0.8253,  ..., -0.8668, -0.8585, -0.6741],\n",
      "        [ 0.7995,  0.8276,  0.2507,  ...,  0.4557,  1.1077,  0.8346]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F #this has activation functions\n",
    "\n",
    "X = df_scaled.drop('Rings', axis=1)\n",
    "y = df_scaled['Rings']\n",
    "\n",
    "#split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=50)\n",
    "\n",
    "\n",
    "# Creating tensors\n",
    "X_train = torch.FloatTensor(X_train.to_numpy())\n",
    "X_test = torch.FloatTensor(X_test.to_numpy())\n",
    "\n",
    "y_train = torch.FloatTensor(y_train.to_numpy())\n",
    "y_test = torch.FloatTensor(y_test.to_numpy())\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self, input_features=7, hidden1=20, hidden2=20, out_features =2):\n",
    "        super().__init__()\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #apply activation functions\n",
    "        x = F.relu(self.layer_1_connection(x))\n",
    "        x = F.relu(self.layer_2_connection(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#instantiate the model\n",
    "model1 = ANN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-955c085b8c1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfinal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1121\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "#run model through multiple epochs/iterations\n",
    "final_loss = []\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = model1.forward(X_train)\n",
    "    loss = loss_function(y_pred, y_train)\n",
    "    final_loss.append(loss)\n",
    "    \n",
    "    if epoch % 10 == 1:\n",
    "        print(f'Epoch number: {epoch} with loss: {loss.item()}')\n",
    "    \n",
    "    optimizer.zero_grad() #zero the gradient before running backwards propagation\n",
    "    loss.backward() #for backward propagation \n",
    "    optimizer.step() #performs one optimization step each epoch   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare the performance of the neural networks to the other model you created. Which performed better? Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of the models I mainly looked at Root mean square error. Based on the abalone dataset, neural networks model performed best having **root mean square error of 0.6280.**\n",
    "Logistic regression accuracy turned out to be very low for this dataset - 0.27 and root mean square error very high - 6.74."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think neural network model performed better because it is known to be better in identifying the relationships and interactions between the model's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
