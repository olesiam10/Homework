{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Take one of the supervised learning models you have built recently and apply at least three dimensionality reduction techniques to it (separately). Be sure to create a short summary of each technique you use. Indicate how each changed the model performance. https://machinelearningmastery.com/dimensionality-reduction-algorithms-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "import pydotplus\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df = pd.read_table(\"australian.dat\", sep=\" \",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "scaler = StandardScaler()\n",
    "normalized_df = credit_df.drop([11], axis=1)\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(normalized_df), columns = normalized_df.columns)\n",
    "scaled = df_scaled.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8840579710144928"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth =10, random_state =50,min_samples_leaf=7,\n",
    "                            min_weight_fraction_leaf=0.2)\n",
    "\n",
    "\n",
    "X = scaled.drop(14, axis=1)\n",
    "y = scaled[14]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        87\n",
      "           1       0.82      0.88      0.85        51\n",
      "\n",
      "    accuracy                           0.88       138\n",
      "   macro avg       0.87      0.88      0.88       138\n",
      "weighted avg       0.89      0.88      0.88       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8297101449275363\n",
      "0.8405797101449275\n"
     ]
    }
   ],
   "source": [
    "#method 1: Singular Value Decomposition/SVD\n",
    "#This technique works really well for dimensionality reduction for sparse data.\n",
    "#Using this technique decreased the model performance\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=7)\n",
    "\n",
    "X_train_svd=svd.fit_transform(X_train)\n",
    "X_test_svd=svd.fit_transform(X_test)\n",
    "\n",
    "model = rf.fit(X_train_svd, y_train)\n",
    "print(model.score(X_train_svd,y_train))\n",
    "\n",
    "model = rf.fit(X_test_svd, y_test)\n",
    "print(model.score(X_test_svd,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8097826086956522\n",
      "0.8405797101449275\n"
     ]
    }
   ],
   "source": [
    "#method 2: Isomap Embedding/Isomap, \n",
    "#This technique creates an embedding of the dataset and attempts to preserve the relationships in the dataset.\n",
    "#Using this technique decreased the model performance but playing with the n components can increasae the model's accuracy\n",
    "from sklearn.manifold import Isomap\n",
    "iso=Isomap(n_components = 7)\n",
    "\n",
    "X_train_iso=iso.fit_transform(X_train)\n",
    "X_test_iso=iso.fit_transform(X_test)\n",
    "\n",
    "model = rf.fit(X_train_iso, y_train)\n",
    "print(model.score(X_train_iso,y_train))\n",
    "\n",
    "model = rf.fit(X_test_iso, y_test)\n",
    "print(model.score(X_test_iso,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7373188405797102\n",
      "0.7608695652173914\n"
     ]
    }
   ],
   "source": [
    "#method 3: Locally Linear Embedding/LLE\n",
    "#This technique creates an embedding of the dataset and attempts to preserve the relationships between neighborhoods in the dataset. \n",
    "#Using this technique decreased the model performance\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "lle=LocallyLinearEmbedding(random_state=47)\n",
    "\n",
    "X_train_lle=lle.fit_transform(X_train)\n",
    "X_test_lle=lle.fit_transform(X_test)\n",
    "\n",
    "model = rf.fit(X_train_lle, y_train)\n",
    "print(model.score(X_train_lle,y_train))\n",
    "\n",
    "model = rf.fit(X_test_lle, y_test)\n",
    "print(model.score(X_test_lle,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write a function that will indicate if an inputted IPv4 address is accurate or not. IP addresses are valid if they have 4 values between 0 and 255 (inclusive), punctuated by periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = \"^((25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])\\.){3}(25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])$\"\n",
    "\n",
    "def accurate(address):\n",
    "    if(re.search(regex, address)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip = '12.345.67.89'\n",
    "accurate(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip = '2.33.245.5'\n",
    "accurate(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
